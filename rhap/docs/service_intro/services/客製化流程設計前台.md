# 客製化流程設計前台

客製化流程設計前台採用三層鬆耦合架構，支援兩種提供模式：1. 結合前端應用平台、API代理伺服器與LLM推論加速器 2. 僅提供前端應用平台。

本服務靈活調度了前端應用平台、API代理伺服器與LLM推論加速器，結合先進的AI工具與工作流程，為用戶提供一個直覺且易於使用的開發環境。用戶無需具備高度的技術背景，便可輕鬆配置並靈活應用各種AI技術，快速實現自動化流程與智能化應用。不僅支援快速佈署，用戶亦能透過前端工具根據具體需求進行介面設計，顯著加速應用的落地。

### **架構介紹**

#### **前端應用平台（Tier 1）**
- 整合開源與專有AI介面，提供完整的AI應用開發環境。
- 支援多種前端介面，可用於AI應用開發，包含AnythingLLM、Open WebUI、DIFY (Workflow Engine)、Streamlit (RAG Workflow)、Aqua (新創企業UnieAI基於OpenWebUI開發之前端)等。
- 搭載Embedding Engine高效能分散式框架，支援嵌入計算與管理，無縫整合至AI工作流程，提升應用效能與可擴展性。

#### **API 代理伺服器（Tier 2）**
- 建構高效能、低成本、安全可靠的AI開發環境。
- 整合多重安全防護工具，利用Safety Guard Proxy打造堅固的資安防護層，確保資料安全無虞。
- 提供輕量化LLM服務，高效能且低資源消耗，讓開發者在有限資源條件下，依然能順暢執行AI推理與應用。
- 內建關聯式資料庫管理系統，支援複雜查詢與大規模應用，確保數據存取與管理的靈活性。
- 整合國網中心計算資源，提供GPU高速運算、GPU容器、CPU虛擬機器、儲存與網路服務，支援AI技術研發與雲端部署。

#### **LLM 推論加速器（Tier 3）**
- 提供Embedding Engine，專為開源文字嵌入模型的部署與應用設計，支援多模型架構，實現高效嵌入提取，強化生成式AI的準確性與運算效率。
- 支援 vLLM 及 Ollama推論框架，透過GPU密集運算處理複雜推論需求。
- 未來將持續整合TGI、UnieInfra(by UnieAI)等更多推論框架，及本土non-GPU解決方案如Neuchips(API)、ITRI QiLai(TVM+LLMI)等，提供更多元推論加速選項。
- 提供TAIDE、Llama、Phi、Mistral、Ministral等開源模型API，並持續更新，確保技術與應用的前瞻性。

### **服務優點**
- 整合並提供各式開源及合作企業開發之前端介面
- 結合AI工具與工作流程，提供直覺易用的開發環境。
- 支援快速佈署，加速應用落地。
- 支援兩種提供模式
  - 針對需要前端、API、推論框架、算力等全方面資源的用戶提供[前端平台（Tier 1）](/docs/service_intro/home.md#架構介紹)、[API代理伺服器（Tier 2）](/docs/service_intro/home.md#架構介紹)、[LLM推論加速器（Tier 3）](/docs/service_intro/home.md#架構介紹)，提供最完整的推論解決方案。
  - 針對僅需要前端介面，想自行串接各式API的用戶，提供僅包含[前端平台（Tier 1）](/docs/service_intro/home.md#架構介紹)的模式，用戶可自行串接 API，靈活開發AI應用。

### **使用情境**
- **自動化業務流程**：企業可根據特定需求設計自動化的業務流程，如電子表單處理、客戶服務自動化、文件分類與管理等，提升工作效率與準確性。
- **智能應用開發**：不具備技術背景的企業或開發者可以通過該平台快速設計並實現具有AI功能的應用，例如智能客服系統、AI推薦引擎、數據分析工具等。
- **跨部門協作**：在跨部門協作過程中，該系統提供了簡單的流程設計工具，可以迅速整合不同部門的需求並協同工作，加快項目推進。





<!--## 三合一集成服務
「三合一集成服務」為RAP 平台提供的三合一解決方案，將前端應用平台、API代理伺服器和 LLM 推論加速器整合為一體，提供無技術背景的用戶搭建私有、獨立與專用的大型語言模型應用服務開發環境。 -->

<!--運用國網中心算力資源，快速搭建具備GPU環境的私有、獨立與專用的LLM大型語言平台，確保資料安全，讓使用者可建立加值應用服務，無需負擔軟硬體建置與維運成本，適合需要專屬與私有LLM 推論服務的使用者。 

-  適合沒有 IT人力或硬體裝置的公司，可以建立專屬和私有的 LLM 推論服務

-  特別是適用於資料不能公開或上傳網路的政府單位或企業，以確保資料安全，提供獨立的 LLM 推論服務

-  無需自備硬體設施，無需購置昂貴的 GPU 裝置，減少投入成本，提供從前端到後端的完整環境

-  高效管理，減少操作繁瑣度，可串接到外部的API Server，或設定串接呼叫自建的 LLM API Server

-  客戶可利用自有資料，把自己訓練或微調過的模型放入本軟體Tier3 服務內，便可使用自己的私有模型

-  易於客戶管理，減少不同系統間整合和管理成本，提供替換進階版的知識庫向量增強檢索專用模型 (Embedding Model) 提升 RAG 能力

## 輕量化前端  
![image](/img/T1.png)  

「輕量化前端」為RAP 平台提供的前端解決方案。僅包含前端應用平台，讓用戶取得靈活的前端推論環境，可以串接自己的API服務，只需要簡單配置就能完成推論工作。   

### 服務優點  

提供精簡型用戶端LLM推論前端應用平台，內建基本的RAG檢索增強生成功能，使用者可依需求自行串接任何LLM API來自建大型語言模型推論服務。適合需要前端服務環境，VCS僅需配置CPU的使用者。 

* 適合已自建 API Server 的客戶  

* 適合具備精進自有大型語言模型能力的單位 

* 超輕量級對話前端環境，適合多種應用場景，無需額外硬體設備 

* 客戶有購買/註冊API key者，即可方便串接各類 API 服務，或可利用前端設置，依需求串接到國網的API Server、也可串接到自行架設的LLM API Server 或 TAIDE API Server 

* 開啟 VCS 即可使用，內建 2 種前端對話系統：AnythingLLM、OpenWebUI 

* 即用即開，免安裝軟體，可節省學習與部署時間。客戶可直接進行 API 服務的推論測試與驗證，適合無法在公司配備電腦上安裝軟體的需求者 

* 節省學習與部署時間，減少客戶的學習成本，無需自行部署建置環境 

* 支援文件上傳並進行 RAG 檢索增強功能：兩種前端系統中均可上傳文件，提升專屬資料查詢的準確性 

* 可解決政府或企業 IT 人員技術量能需求與無硬體資源不足的問題 


<!--

# 前端平台


AnythingLLM 和 OpenWebUI 是 RAP 平台的前端推論解決方案組，位於前端平台，負責處理使用者的請求並提供直觀的圖形化界面。簡單操作，便於新手使用。


## AnythingLLM 

AnythingLLM 是最容易使用的多合一 AI 應用程式，它可以執行 RAG、AI Agents 以及更多的功能，而且不需要任何程式碼或基礎架構。


- 零設定、私有化、全方位的 AI 應用：無需繁瑣的開發者設定，提供本地 LLM、RAG 和 AI Agent 的一站式解決方案。
- AI Agents 功能：具備代理（Agent）特性，能夠自動執行一系列任務，提高效率和生產力。
- 完全可客製化：適用於企業或組織，提供與 ChatGPT 相當的完整功能，並具備權限控制，支持任何 LLM、嵌入模型或向量數據庫。
- 無程式碼或基礎架構負擔：使用者無需編寫程式碼或處理複雜的基礎設施，即可享受強大的 AI 功能。

如果想了解 AnythingLLM 的操作，可以參考 [AnythingLLM  使用說明](/docs/tools/AnythingLLM%20使用說明.md)


## OpenWebUI
OpenWebUI 是一個可擴充、功能豐富且易於使用的 AI 介面，設計為完全離線運行。它支持多種大型語言模型（LLM），包括 Ollama 和相容 OpenAI 的 API。其主要特點包括：

- 完全離線運行：無需連線網路即可使用，確保數據的隱私和安全。
- 多樣化的 LLM 支持：相容多種 LLM 運行器，提供靈活的模型選擇，如 Ollama 和 OpenAI 相容的 API。
- 可擴充性：設計為可擴充的架構，允許開發者添加新的功能和擴充軟體，滿足不同的需求。
- 使用者友好：提供直觀的界面和豐富的功能，使得無論是初學者還是專業人士都能輕鬆使用。

如果想了解 OpenWebUI 的操作，可以參考 [Open WebUI 使用說明](/docs/tools/OpenWebUI%20使用說明.md)


# 模型設定

對於AnythingLLM 跟 OpenWebUI 安裝後要如何將模型正確導入有不同的設定
<br />

可以參考 [AnythingLLM 的模型設定](/docs/tools/AnythingLLM%20使用說明.md#模型設定)跟 [OpenWebUI 的模型設定](/docs/tools/OpenWebUI%20使用說明.md#模型設定)

-->