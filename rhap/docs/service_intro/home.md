---
title: "國網中心大型語言模型推論服務"
---
import Head from '@docusaurus/Head';

<Head>
  <title>Home | NCHC RHAP</title>
</Head>

## 認識 RHAP  

**TAIWAN AI RHAP 臺灣睿普平台（以下簡稱 RHAP）** 由 **國家實驗研究院 國家高速網路與計算中心**（**國網中心，NCHC**）推出，是一款高效能 AI 平台。RHAP的核心技術為 **TAIDE 大型語言模型**（**Trustworthy AI Dialogue Engine，可信任人工智慧對話引擎**），並搭載 **RAG（檢索增強生成）技術**，提供更準確的語意回應，並可根據特定需求進行優化。  

RHAP 整合**生成式 AI 應用開發**所需的全方位資源，涵蓋**基礎層算力、模型層、開發工具** 及 **部署環境**，大幅降低 AI 應用開發門檻，使各領域能夠輕鬆建立專屬 AI 解決方案。  

RHAP 的服務重點聚焦於**政府部門資料庫、文件、公文檔案**等應用場景，內建**五大核心功能**：  
- **自動摘要**  
- **文章撰寫**  
- **公文撰寫**  
- **中翻英**  
- **英翻中**  

經由此五大功能，亦延伸出適合政府部門應用之四大任務：
- **公文撰寫**
- **新聞稿撰寫**
- **民眾陳情**
- **模擬問答**

當然，RHAP平台不僅能為政府部門提供便利的服務，也致力於和**政府、學術研究單位**及**新創企業、中小企業、資服業者**等企業類型合作，不僅能提供**推論服務及算力**，亦支援**模型微調**等**專屬領域客製化服務**，可廣泛應用於：
- **知識管理**
- **產品研發管理**
- **自動文案生成**
- **文獻檢索與分析**  

等領域，協助新創企業、政府機構、學術研究等單位更快速、精準地開發並部署客製化AI應用，提升工作效率與服務品質。  

---

## 為何您應該選擇 RHAP？  

### 軟體優勢
- RHAP建構於**TAIDE大型語言模型之上**，專為臺灣企業需求設計，支援繁體中文優化，使模型回應更符合本地需求，打造具**主權AI**概念的本土化解決方案。
- RHAP採用**開源架構**，致力於整合**開源軟體工具**與**國內各企業解決方案**。無論是前端、中介層或是模型等來自外界的LLM解決方案，皆可整合至RHAP服務框架內提供，打造臺灣專屬之AI Tribe生態聚落，推動 AI 產業創新與生態系發展。
- RHAP不僅支援本土TAIDE系列模型，亦**支援國際主流之基礎及專業開源模型**，如Meta Llama、Microsoft Phi、Mistral系列等，並透過API提供無縫整合服務，企業可靈活選用最適合自身需求的模型。
### 硬體優勢  
- RHAP由國網中心開發，而國網中心為臺灣唯一專注於**共用大型計算平台與學術研究網路服務**的研究機構，具備**高效能計算（HPC）、儲存、網路、平台整合** 及 **大數據分析**能力，為臺灣科技發展奠定堅實基礎。  
- 國網中心依託**超級電腦「創進一號」**、**「台灣杉 3 號」**及**100G 高速網路**，提供 **高效能運算（AIHPC）** 及 **獨立機敏資料庫**，確保高效能與資訊安全。
- RHAP支援「地端」、「雲端」、「地端+雲端」部署，相較一般雲端服務商，RHAP的方案更方便客戶依需求客製化設計。
- RHAP不僅支援Nvidia GPU，更**支援國內的推論硬體加速卡及其他廠牌GPU**，透過「混合式+異質性」的LLM推論引擎提供高度的**高可用性(High Availability)**及**平衡附載(Load Balancing)**。


---

## 開始使用RHAP  

**RHAP**提供多種服務模式，以滿足不同應用需求。  

### 1. [客製化流程設計前台](/docs/service_intro/services/可客製化流程設計服務前台)  

RHAP的「客製化流程設計前台」提供 **「三合一集成服務」（Hydra）** 與 **「輕量化前端」（Hummingbird）** 兩項子服務，整合開源前端服務，並搭載國網中心自研 **RAG 系統**，讓使用者能夠量身打造 **客製化 AI 工作流程**。  
- **「三合一集成服務」（Hydra）**：結合 **[前端平台](/docs/service_intro/home.md#架構介紹)、[API代理伺服器](/docs/service_intro/home.md#架構介紹)、[LLM推論加速器](/docs/service_intro/home.md#架構介紹)**，提供最完整的推論解決方案。  
- **「輕量化前端」（Hummingbird）**：專為 API 串接設計的靈活開發模式，用戶可自行串接 API，快速部署 AI 應用。  

### 2. [多模型API服務](/docs/service_intro/services/高效能多模型API服務)  

**多模型API服務（Medusa）** 整合 **API 代理伺服器** 與 **LLM 推論加速器**，提供標準化 API 介面及 **安全控制機制（Safety Guard）**，讓使用者可透過 API 租用方式快速建立 LLM 應用服務。RHAP 提供 **TAIDE 模型** 及多種開源模型，使企業無需高昂的硬體投入，即可快速、安全地開發 AI 應用。  

### 3. [模型微調與評估](/docs/service_intro/services/模型微調訓練與評估流程)  

RHAP提供的**模型微調與評估服務**，包含：  
- **資料生成與品質評估**  
- **模型微調訓練**  
- **模型表現評估**  

使用者無需具備模型微調技術，即可透過RHAP平台 **簡單快速地進行模型微調與優化**，確保 AI 模型始終保持高效與準確。  

---

## RHAP如何建構服務架構？  

### 一、「客製化流程設計前台」、「多模型API服務」：鬆耦合架構

RHAP所提供的「客製化流程設計前台」及「多模型API服務」採用**三層鬆耦合（Loosely Coupled）架構設計**，透過開源軟體將不同功能模組分層，以滿足多樣化的推論需求，確保**高效能與靈活性**。 

### **1. 前端應用平台**  
- 提供基礎推論能力，適用於 **低延遲、單一請求** 的應用，如客服對話、自動文本生成等。  
- 可獨立運行，亦可搭配 API 代理伺服器與 LLM 推論加速器，實現更進階應用。  

### **2. API 代理伺服器**  
- 作為 **中介層**，負責接收前端請求、進行多步驟處理，並執行 **安全控制**。  
- 內建 **LiteLLM** 進行基礎推論，並結合 **Guardrail 技術** 確保資料安全與合規。  
- 通常與 LLM 推論加速器整合運行，提供高效能 AI 服務。  

### **3. LLM 推論加速器**  
- **支援 vLLM 及 Ollama 模型**，負責深度推理與高效能計算，透過 **GPU 密集運算** 處理複雜推論需求。  
- **TEI（Embedding Engine）** 強化生成式 AI 的準確性與運算效率。  
- 與 **API 代理伺服器** 深度整合，確保高可靠性與安全性。  


### 二、「模型微調與評估」：CI工具整合開發流程

RHAP 提供的「模型微調與評估」服務，透過 Jenkins 等持續整合 (CI) 工具，將模型優化所需的多個步驟串接起來，形成一個完整且流暢的開發流程。此服務涵蓋資料生成與精煉、模型微調訓練、以及模型效能評估，使使用者能夠在最少的技術門檻下，高效完成模型優化與驗證。