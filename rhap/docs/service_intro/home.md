---
title: "國網中心大型語言模型推論服務"
---
import Head from '@docusaurus/Head';

<Head>
  <title>Home | NCHC RHAP</title>
</Head>

## 認識 RHAP  

**TAIWAN AI RHAP 臺灣睿普平台（以下簡稱 RHAP）** 由 **國家實驗研究院 國家高速網路與計算中心**（**國網中心，NCHC**）推出，是一款高效能 AI 平台。RHAP的核心技術為 **TAIDE 大型語言模型**（**Trustworthy AI Dialogue Engine，可信任人工智慧對話引擎**），並搭載 **RAG（檢索增強生成）技術**，提供更準確的語意回應，並可根據特定需求進行優化。  

RHAP 整合**生成式 AI 應用開發**所需的全方位資源，涵蓋**基礎層算力、模型層、開發工具** 及 **部署環境**，大幅降低 AI 應用開發門檻，使各領域能夠輕鬆建立專屬 AI 解決方案。  

RHAP 的服務重點聚焦於**政府部門資料庫、文件、公文檔案**等應用場景，內建 **五大核心功能**：  
- **自動摘要**  
- **文章撰寫**  
- **公文撰寫**  
- **中文翻譯為英文**  
- **英文翻譯為中文**  

此外，RHAP平台支援**模型微調**等**專屬領域客製化服務**，可廣泛應用於**知識管理、產品研發管理、自動文案生成、文獻檢索與分析** 等領域，協助 **新創企業、政府機構、學術研究單位** 更快速、精準地開發並部署客製化 AI 模型，提升工作效率與服務品質。  

---

## 為何選擇 RHAP？  

- **RHAP 建構於TAIDE大型語言模型之上**，專為臺灣市場設計，支援繁體中文優化，使模型回應更符合本地需求，打造具**主權 AI**概念的本土化解決方案。  
- **國網中心為臺灣唯一專注於共用大型計算平台與學術研究網路服務的研究機構**，具備**高效能計算（HPC）、儲存、網路、平台整合** 及 **大數據分析**能力，為臺灣科技發展奠定堅實基礎。  
- **國網中心依託超級電腦「創進一號」、「台灣杉 3 號」及 100G 高速網路**，提供 **高效能運算（AIHPC）** 及 **獨立機敏資料庫**，並整合開源軟體工具與 AI 支援服務，推動 AI 產業創新與生態系發展。  

---

## 開始使用RHAP  

**RHAP**提供多種服務模式，以滿足不同應用需求。  

### 1. [客製化流程設計前台](/docs/service_intro/services/可客製化流程設計服務前台)  

RHAP提供 **「三合一集成服務」（Hydra）** 與 **「輕量化前端」（Hummingbird）** 兩大服務，整合開源前端服務，並搭載國網中心自研 **RAG 系統**，讓使用者能夠量身打造 **客製化 AI 工作流程**。  
- **「三合一集成服務」（Hydra）**：結合 **[前端平台](/docs/service_intro/home.md#架構介紹)、[API代理伺服器](/docs/service_intro/home.md#架構介紹)、[LLM推論加速器](/docs/service_intro/home.md#架構介紹)**，提供最完整的推論解決方案。  
- **「輕量化前端」（Hummingbird）**：專為 API 串接設計的靈活開發模式，用戶可自行串接 API，快速部署 AI 應用。  

### 2. [多模型API服務](/docs/service_intro/services/高效能多模型API服務)  

**多模型API服務（Medusa）** 整合 **API 代理伺服器** 與 **LLM 推論加速器**，提供標準化 API 介面及 **安全控制機制（Safety Guard）**，讓使用者可透過 API 租用方式快速建立 LLM 應用服務。RHAP 提供 **TAIDE 模型** 及多種開源模型，使企業無需高昂的硬體投入，即可快速、安全地開發 AI 應用。  

### 3. [模型微調與評估](/docs/service_intro/services/模型微調訓練與評估流程)  

RHAP提供的**模型微調與評估服務**，包含：  
- **資料生成與品質評估**  
- **模型微調訓練**  
- **模型表現評估**  

使用者無需具備模型微調技術，即可透過RHAP平台 **簡單快速地進行模型微調與優化**，確保 AI 模型始終保持高效與準確。  

---

## RHAP如何建構服務架構？  

RHAP 採用 **三層鬆耦合（Loosely Coupled）架構設計**，透過開源軟體將不同功能模組分層，以滿足多樣化的推論需求，確保**高效能與靈活性**。 

### **1. 前端應用平台**  
- 提供基礎推論能力，適用於 **低延遲、單一請求** 的應用，如客服對話、自動文本生成等。  
- 可獨立運行，亦可搭配 API 代理伺服器與 LLM 推論加速器，實現更進階應用。  

### **2. API 代理伺服器**  
- 作為 **中介層**，負責接收前端請求、進行多步驟處理，並執行 **安全控制**。  
- 內建 **LiteLLM** 進行基礎推論，並結合 **Guardrail 技術** 確保資料安全與合規。  
- 通常與 LLM 推論加速器整合運行，提供高效能 AI 服務。  

### **3. LLM 推論加速器**  
- **支援 vLLM 及 Ollama 模型**，負責深度推理與高效能計算，透過 **GPU 密集運算** 處理複雜推論需求。  
- **TEI（Embedding Engine）** 強化生成式 AI 的準確性與運算效率。  
- 與 **API 代理伺服器** 深度整合，確保高可靠性與安全性。  
