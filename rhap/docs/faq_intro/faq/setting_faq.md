# 部署與設定

## 安裝與管理虛擬機

**1. 如何安裝虛擬機？**

登入 「TWCC」，選擇「虛擬運算（VCS）」建立Ubuntu虛擬機。若要啟用三合一集成服務(Hydra)，請選擇一顆以上的GPU，系統磁碟容量200G以上。

**2. 如何連線虛擬運算個體？**

在TWCC下，當虛擬運算個體在「Ready」的狀態下，按下「連線」，打開終端機，依畫面說明鍵入進行連線。

**3. 如何管理允許連入、連出的網段？**

建立虛擬運算個體時，選擇「建立安全性群組」，設定網路類型、連接埠、CIDR等。

## 安裝**三合一集成服務**

**1. 如何安裝三合一集成服務(Hydra)？**

連線虛擬機後，需打開80的連接埠，進入目錄，開始進行下列步驟：

l   進入 hydra 資料夾：cd \~/hydra/

l   編輯 values.yaml 文件，在其中新增模型區塊，設定模型來源（Ollama, Hugging Face, OpenAI），並提供 token 和所需參數。若來源相同，可直接更改現有模型名稱。

l   執行 step2.sh：./step2.sh -f values.yaml

l   確認下載狀況：使用 docker ps 檢查容器，進入模型容器並確認 ollama ls 顯示模型是否下載成功。

## 技術問題

### 前端使用

1.**如何在 OpenWebUI 上建立知識庫並取用?**

本指南將協助您完成 Open WebUI Knowledge Base 的管理與取用，並通過導入自定義知識庫文件來搭建 RAG（Retrieval-Augmented Generation）服務。您將學習如何準備、管理與使用知識庫，並快速針對知識庫內容做詰問。

---

**前置作業**

在開始搭建知識庫之前，請確保您已準備好知識庫所需之文件。支持的文件格式包括 .txt、.doc 和 .pdf。以下為準備文件時的重點提示：[​](http://103.124.72.16.sslip.io:3000/docs/faq_intro/faq/RAG#%E5%89%8D%E7%BD%AE%E4%BD%9C%E6%A5%AD "前置作業的直接連結")

(1) **文本分割**：
   * LLM（大型語言模型）具有 token 長度限制，導入向量庫時系統會自動將長文本拆分為較小的片段。每段文本作為一個知識單位存儲。  

(2) **處理表格和圖片**：
   * 若文件中包含表格或圖片，Open WebUI 和相關框架（如 LangChain）僅能處理文字部分。
   * 如需使用圖片中的信息，建議先通過 OCR 工具提取文字內容，或使用文檔轉換工具（如 WPS）將其轉換為文本格式。

---

以下為範例 `.txt `文件，包含多個段落、適合用於測試。

`請你來扮演我們公司的電商銷售，擅長以幽默風趣的語氣吸引顧客下單，並且能夠用成語來形容我們的產品。我們公司的零食有：小魚干、花生、雞腿、鴨脖、面包、豆干等。飲料有：可樂、芬達、美年達、雪碧、橙汁、蘋果醋、葡萄汁等。銷量最高的是可樂。我們的老闆是張三，他最愛的零食是雞腿，他最愛的飲料是可樂。`

---

**知識庫的建立與管理**[​](http://103.124.72.16.sslip.io:3000/docs/faq_intro/faq/RAG#%E7%9F%A5%E8%AD%98%E5%BA%AB%E7%9A%84%E5%BB%BA%E7%AB%8B%E8%88%87%E7%AE%A1%E7%90%86 "知識庫的建立與管理的直接連結")

完成上述準備後，您將進一步操作來管理與使用知識庫。

(1) **創建工作區與知識庫**：
   * 進入 Open WebUI 的工作區，點選「知識」選項。
   * 點選右側的 `+` 按鈕，依據需求輸入知識庫的基本資訊（此資訊僅供辨識，對實際功能無影響）。
   * 創建成功後，系統會自動進入該知識庫的管理頁面。  

(2) **新增知識庫內容**：
   * 在管理頁面中，再次點選 `+` 按鈕。
   * 根據需求，選擇以下四種新增方式之一：
     * 上傳文件
     * 上傳資料夾
     * 使用本機文件替換現有內容
     * 手動新增文本內容
   * 以「上傳檔案」為例：選擇文件後，確認上傳完成，即可在知識庫中看到該文件。

(3) **檢查與驗證**：
   * 返回主頁，於對話框輸入 `#` 符號，即可選擇需要使用的知識庫。
   * 每次僅可新增一個知識庫至會話中。
   * 開始針對知識庫內容提問，並檢查輸出結果是否符合預期。  

---

#### 使用說明與權限分配[​](http://103.124.72.16.sslip.io:3000/docs/faq_intro/faq/RAG#%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E6%AC%8A%E9%99%90%E5%88%86%E9%85%8D "使用說明與權限分配的直接連結")

* **管理員功能**：
  * 管理員可以進入工作區進一步新增、修改與刪除知識庫內容。
  * 透過 `#` 符號取用現有的知識庫內容進行查詢與交互。
* **使用者權限**：
  * 一般使用者無法進入工作區管理知識庫。
  * 透過 `#` 符號取用現有的知識庫內容進行查詢與交互。

---

至此，您應能成功搭建並使用基於知識庫的 RAG 服務，滿足快速詰問知識庫內容的需求。

如欲更了解知識庫，可參考 [Open WebUI 知識庫文檔](https://docs.openwebui.com/features/workspace/knowledge/)。

### **模型下載與啟用**

**1. 為什麼我從 Hugging Face 或 Ollama 下載的模型無法使用？**

可能原因：

l   模型尚在下載或載入中： 模型在下載或載入過程中需要時間，請稍待片刻再嘗試使用。

l   不支援 vLLM 框架： 部分模型可能不兼容 vLLM，請確認所下載的模型是否支援 vLLM。

確認方式：

l   檢查容器日誌： 使用 docker logs \<容器名稱\> 命令查看模型容器的日誌，確認下載或載入的進度。

l   檢查支援性： 在日誌中查找與 vLLM 支援相關的錯誤或警告訊息，判斷模型是否適用。

**2. 為什麼已按照說明啟動，但無法使用模型？**

可能原因： vLLM 在載入模型時需一些時間，尤其是大型模型載入時間更長，請稍等直到載入完成。

確認方式： 使用 docker logs \<容器名稱\> 查看載入進度，確認是否載入完成。

**3. 為什麼新增的模型沒有成功出現在前台？**

可能原因：

l   提供的來源 token 錯誤

l   step2.sh 腳本執行失敗

l   虛擬機 (VM) 硬碟空間不足

l   values.yaml 內的模型區塊設置錯誤

l   IDE 未儲存更改

初步解決方案：

l   重啟相關容器：

docker-compose down

docker-compose up

docker ps # 確認容器已重啟

l   重新啟動 IDE（若使用 remote SSH，需重連到主機）。

l   重跑 step2.sh。

l   確認 VM 空間：

du -sh \*

df –h

### 模型使用

**1. 為何 OpenWebUI 前台的特定模型無法正常回應？**

可能原因：

l   模態錯誤：下載的可能是非對話模型（如詞嵌入模型）或其他任務類型（如安全防護模型）的模型。

l   無存取權限：如TAIDE模型需要申請API Token且具有存取權限，否則會報錯。

l   未設定 chat completion 模板：例如 Ollama 模型，需依據說明文件設定 chat completion。

l   內容或語言限制： 可能因內容觸發 content filter 或模型不支援輸入語言，建議參考該模型說明文件。

l   計費問題：使用額度（錢包餘額）用罄，導致模型無法使用。

**2. 我遇到模型有Token限制，該怎麼辦？**

此問題與您使用的模型版本新舊有關，版本較舊的部分模型有著程度不同的Token限制，若有大量token使用需求，建議可以選擇版本較新的模型。