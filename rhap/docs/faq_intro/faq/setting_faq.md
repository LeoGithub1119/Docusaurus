# 部署與設定

## 安裝與管理虛擬機

### 1. 如何安裝虛擬機？
登入 **TWCC**，選擇「虛擬運算（VCS）」建立 Ubuntu 虛擬機。若要啟用三合一集成服務（Hydra），請選擇 **一顆以上的 GPU**，並將系統磁碟容量設定 **200G 以上**。

### 2. 如何連線虛擬運算個體？
在 TWCC 下，當虛擬運算個體狀態為 **Ready** 時，按下「連線」，打開終端機，依畫面說明鍵入進行連線。

### 3. 如何管理允許連入、連出的網段？
建立虛擬運算個體時，選擇 **「建立安全性群組」**，設定 **網路類型、連接埠、CIDR** 等參數。

---

## 技術問題

### 前端使用
#### 1. 如何在 OpenWebUI 上建立知識庫並取用？
本指南協助您管理 OpenWebUI 的知識庫，並通過自定義知識庫文件搭建 RAG（Retrieval-Augmented Generation）服務，以滿足快速詰問的需求。

#### 前置作業
- 支持的文件格式：`.txt`、`.doc`、`.pdf`
- 重要提示：
  - **文本分割**：長文本會自動拆分為較小片段，作為知識單位。
  - **處理表格與圖片**：系統僅處理文字部分，建議用 **OCR** 工具轉換圖片內文字。

#### 知識庫的建立與管理
1. **創建工作區與知識庫**
   - 進入 OpenWebUI 的工作區，點選「知識」選項，按下 **+**，輸入基本資訊。

2. **新增知識庫內容**
   - 上傳文件、資料夾
   - 使用本機文件替換內容
   - 手動新增文本內容

3. **檢查與驗證**
   - 透過 `#` 符號選擇並啟用知識庫
   - 開始提問並檢查輸出結果是否符合預期

#### 使用說明與權限分配
- **管理員功能**：可新增、修改、刪除知識庫內容
- **使用者權限**：僅能取用現有知識庫進行查詢

---

## 模型下載與啟用

### 1. 為什麼從 Hugging Face 或 Ollama 下載的模型無法使用？
- 可能原因：
  - **模型下載或載入中**
  - **不支援 vLLM 框架**
- 確認方式：
  - 使用 `docker logs <容器名稱>` 查看日誌

### 2. 已按照說明啟動，但無法使用模型？
- 原因：大型模型載入時間較長
- 確認方式：`docker logs <容器名稱>` 檢查進度

### 3. 新增的模型無法顯示在前台？
- 可能原因：
  - 提供的來源 token 錯誤
  - step2.sh 腳本執行失敗
  - VM 硬碟空間不足
- 解決方案：
  - 重啟容器：
    ```bash
    docker-compose down
    docker-compose up
    docker ps
    ```
  - 重新連接 IDE

---

## 模型使用

### 1. 為何特定模型無法正常回應？
- 可能原因：
  - **模態錯誤**：非對話模型或其他任務類型
  - **無存取權限**
  - **未設定 chat completion 模板**
  - **語言或內容限制**
  - **計費問題**

### 2. 遇到 Token 限制該怎麼辦？
- 版本較舊的模型有 Token 限制
- 若有大量 Token 需求，建議選擇版本較新的模型


